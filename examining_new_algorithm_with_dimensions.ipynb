{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c6f9b71-b845-4bd8-a06e-ac504370abdb",
   "metadata": {},
   "source": [
    "# Examing the New Algorithm with Different Vector Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b1a55c-fc16-4202-b9b4-8879551d0c0c",
   "metadata": {},
   "source": [
    "This notebook is an extension of the \"examing_new_algorithm_with_cutoffs\" notebook. It shares similar functions but they are modified to deal with the new file locations and data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c613e45e-f2b6-455f-8bf9-ef3b6353baf2",
   "metadata": {},
   "source": [
    "### Required Functions for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8d7cc5c-c8aa-433f-9ca9-adcf155ea5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions and imports\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def TotalStoryAnalysis(story_id, cc_index_in_file_values, dimension_values):\n",
    "    \n",
    "    '''\n",
    "    This functions runs a for loop to run an analysis for each dimension value of the story. It adds the results to the saved_data list.\n",
    "    \n",
    "    Inputs: \n",
    "        story_id: Unique integer identifier of the desired story\n",
    "        cc_index_in_file_values: A list of values that indicates the index of the most representative vector representation of the story. There are as many values in this list as there are total dimension.\n",
    "        dimension_values: a list of integers that represent the dimensions of the vectors\n",
    "     \n",
    "    '''\n",
    "    \n",
    "    for i in range(len(dimension_values)): \n",
    "        dimension = dimension_values[i]\n",
    "        cc_index_in_file = cc_index_in_file_values[i]\n",
    "\n",
    "        precision, recall, fpr, f1 = SingleFileAnalysis(f'data/new_algorithm_files/story_{story_id}/story_{story_id}_dimension_{dimension}.json', story_id, cc_index_in_file)\n",
    "        \n",
    "        # appending to saved_data which is a global variable\n",
    "        row = {'story_id': story_id, 'dimension_value': dimension, 'precision': precision, 'recall': recall, 'fpr': fpr, 'f1': f1} \n",
    "        saved_data.append(row)\n",
    "\n",
    "def SingleFileAnalysis(file_path, story_id, cc_index_in_file):\n",
    "    \n",
    "    ''''\n",
    "    \n",
    "    \n",
    "    Inputs: \n",
    "        file_path: The path to the file for analysis\n",
    "        story_id: Unique integer number for the story\n",
    "        cc_index_in_file: This is the integer position for where the connected component that best represents the story is found in the new data\n",
    "        \n",
    "    Outputs:\n",
    "        Precision\n",
    "        Recall\n",
    "        fpr\n",
    "        f1\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    story_data = loadJsonFile(file_path)\n",
    "    \n",
    "    exemplar_links = GetExamplarLinks(story_id)\n",
    "\n",
    "    story_links = story_data['story_vectors'][cc_index_in_file]['con_comps']\n",
    "    \n",
    "    tn = defineTrueNegatives(story_data, exemplar_links, cc_index_in_file)\n",
    "    \n",
    "    bot_graphs = getFormattedBotGraphs(story_links)\n",
    "    \n",
    "    tp, fp, fn, failed_bots = defineConfusionMatrix(bot_graphs, exemplar_links, want_failed_bots = True)\n",
    "    \n",
    "    precision, recall, fpr, f1 = getScores(tp, tn, fp, fn)\n",
    "    \n",
    "    return precision, recall, fpr, f1\n",
    "\n",
    "def loadJsonFile(file_path, encoding = 'UTF-8'):\n",
    "    '''\n",
    "    Function to load in the JSON data\n",
    "    \n",
    "    Inputs:\n",
    "        file_path: The path to the file\n",
    "        encoding: The desired encoding to load the file in\n",
    "        \n",
    "    returns:\n",
    "        story_data: The contents of the provided json file\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    file = open(file_path, encoding = 'UTF-8')\n",
    "    story_data = json.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    return story_data\n",
    "\n",
    "def GetExamplarLinks(story_id, file_path = 'data/exemplar_dataset.json'):\n",
    "    '''\n",
    "    This function loads in the exemplar dataset and returns the data for the given story by its ID\n",
    "    \n",
    "    Input:\n",
    "        story_id: The unique number given to the story to identify it\n",
    "        file_path: Optional input that points to the exemplar data set file\n",
    "        \n",
    "    Returns:\n",
    "        exemplar_links: List of dictionary objects that each represent one connected component of the story. \n",
    "    '''\n",
    "    \n",
    "    file = open(file_path)\n",
    "    exemplar = json.load(file)\n",
    "    file.close()\n",
    "\n",
    "    exemplar_links = exemplar[story_id]['links']\n",
    "    \n",
    "    return exemplar_links\n",
    "\n",
    "def defineConfusionMatrix(bot_graphs, exemplar_links, want_failed_bots = False):\n",
    "    '''\n",
    "    Function to calculate the True Positive (tp), False Positive (fp), and False Negative (fn) values.\n",
    "    \n",
    "    inputs:\n",
    "        bot_graphs: A list of dictionaries that represent each graph. The ouput of getUniqueGraphs().\n",
    "        exemplar_links: A list of dictionaries that represent each graph. The ouput of getFormattedBotGraphs().\n",
    "    \n",
    "    returns: \n",
    "        tp: an integer for the true positives\n",
    "        fp: an integer for the false positives\n",
    "        fn: an integer for the false negatives\n",
    "        bot_failed_attempts: a list of dictionaries for each graph not found in the exemplar data set\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    #creating a list of the links found in the exemplar dataset\n",
    "    exemplar_link_list = [i['graph_link'] for i in exemplar_links]\n",
    "    \n",
    "    # list to identify any failed attempts\n",
    "    bot_failed_attempts = [] \n",
    "    \n",
    "    # setting values for the true positives, false positives, and false negatives\n",
    "    tp = 0   \n",
    "    fp = 0 \n",
    "    fn = 0 \n",
    "    \n",
    "    \n",
    "    for graph in bot_graphs:\n",
    "        \n",
    "        # looking at each uri from the storygraphbot ouput and seeing that it is in the exemplar data set\n",
    "        if graph['graph_link'] in exemplar_link_list:\n",
    "            \n",
    "            # finding the index where the uri is found in the exemplar data set\n",
    "            idx = exemplar_link_list.index(graph['graph_link']) \n",
    "    \n",
    "            # checking that the degrees of the connected components match where the uri of each matched\n",
    "            # the degree of the storygraphbot output is rounded to 2 decimals because it is a long decimal while\n",
    "            # the exemplar is only 2 digits\n",
    "            \n",
    "            \n",
    "            if (round(graph['cc_degree'], 2)) == (exemplar_links[idx]['cc_degree']) and (graph['cc_index'] == (exemplar_links[idx]['cc_index'] - 1)): \n",
    "                \n",
    "                tp += 1\n",
    "\n",
    "            else:\n",
    "                \n",
    "                # adding to false postive when the storygraphbot output has the correct graph uri but the wrong connected component degree\n",
    "                fp += 1\n",
    "                bot_failed_attempts.append(graph)\n",
    "       \n",
    "        else:\n",
    "            # adding to the false positive when the storygraphbot ouput uri is not found in the exemplar\n",
    "            fp += 1\n",
    "            bot_failed_attempts.append(graph)\n",
    "    \n",
    "    # bot links is a link of uri's ouputed by the storygraphbot algoirthm\n",
    "    bot_links = [bot_graphs[i]['graph_link'] for i in range(len(bot_graphs))]\n",
    "    \n",
    "    #looking at each link in the exemplar links\n",
    "    for link in exemplar_link_list:\n",
    "        \n",
    "        if link not in bot_links:\n",
    "            \n",
    "            # adding to the false negative because a link in the exemplar is not found in the storygraphbot output\n",
    "            fn += 1\n",
    "            \n",
    "    if want_failed_bots == True:\n",
    "        \n",
    "        return tp, fp, fn, bot_failed_attempts\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return tp, fp, fn\n",
    "\n",
    "    \n",
    "def defineTrueNegatives(story_data, exemplar_links, cc_index_in_file):\n",
    "    '''\n",
    "    Inputs: \n",
    "        story_data: List of each vector in the JSON file that is produced from the loadJsonFile function \n",
    "        exemplar_links: \n",
    "        cc_index_in_file: The integer index that points to where the desired story is found in the JSON file \n",
    "    \n",
    "    Outputs:\n",
    "        tn: The number of true negatives\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    tn = 0\n",
    "    \n",
    "    #creating a list of the links found in the exemplar dataset\n",
    "    exemplar_link_list = [i['graph_link'] for i in exemplar_links]\n",
    "    \n",
    "    non_story_data = story_data['story_vectors'][:cc_index_in_file] + story_data['story_vectors'][cc_index_in_file+1:]\n",
    "    \n",
    "    for story in non_story_data:\n",
    "        \n",
    "        bot_graphs = getFormattedBotGraphs(story['con_comps'])\n",
    "        \n",
    "        # want to add to TN when a connected component not included in the main story is not in the exemplar list\n",
    "        for graph in bot_graphs:\n",
    "            \n",
    "            if graph['graph_link'] not in exemplar_link_list:\n",
    "                \n",
    "                tn += 1\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # finding the index where the uri is found in the exemplar data set\n",
    "                idx = exemplar_link_list.index(graph['graph_link']) \n",
    "                \n",
    "                # adding to true negative when the graph does not have the same degree or index as the one found in the exemplar list\n",
    "                # this means it is different than the connected component in the exemplar and was correctly not added to the story \n",
    "                \n",
    "                if (round(graph['cc_degree'], 2)) != (exemplar_links[idx]['cc_degree']) or (graph['cc_index'] != (exemplar_links[idx]['cc_index'] - 1)): \n",
    "                \n",
    "                    tn += 1\n",
    "                    \n",
    "                \n",
    "    return tn\n",
    "\n",
    "def getFormattedBotGraphs(unique_graphs):\n",
    "    '''\n",
    "    A function that transforms the storygraph bot format to the exemplar format for direct comparison\n",
    "    \n",
    "    inputs:\n",
    "        unique_graphs: A list of dictionaries that each represent a graph in the storygraphbot format.\n",
    "        \n",
    "    outputs:\n",
    "        bot_graphs: A list of dictionaries that each represent a graph in the exemplar format.\n",
    "    '''\n",
    "    \n",
    "    # list to append the dictionary to\n",
    "    bot_graphs = []\n",
    "    \n",
    "    for graph in unique_graphs:\n",
    "        # creating a dictionary for the new formating\n",
    "        graph_dic = {'graph_link': '', 'cc_degree': '', 'cc_index': ''} \n",
    "        \n",
    "        # transforming the graph link from the internet archive format to the csu format\n",
    "        intermediate = (graph['graph_uri']\n",
    "                                   .replace('https://web.archive.org/storygraph/graphs/usa/', 'https://storygraph.cs.odu.edu/graphs/polar-media-consensus-graph/')\n",
    "                                   .replace('hist=144', 'hist=1440'))\n",
    "        graph_dic['graph_link'] = (intermediate\n",
    "                                   .replace(intermediate[65:87], '')\n",
    "                                   .replace('&cursor', '#cursor') + intermediate[65:87].replace('#t=', '&t='))\n",
    "\n",
    "        # storing the connected component degree\n",
    "        graph_dic['cc_degree'] = graph['avg_degree'] \n",
    "        \n",
    "        # storing the uri with the most edges in the connected component\n",
    "        graph_dic['cc_index'] = graph['index'] \n",
    "        \n",
    "        bot_graphs.append(graph_dic)\n",
    "        \n",
    "    return bot_graphs\n",
    "\n",
    "def getScores(tp, tn, fp, fn):\n",
    "    '''\n",
    "    tp = True Positive\n",
    "    tn = True Negative\n",
    "    fp = False Positive\n",
    "    fn = False Negatives\n",
    "    \n",
    "    return: percision, recall, f1-score\n",
    "    '''\n",
    "    # calculating the precision, recall, and f1-score\n",
    "    \n",
    "    precision = ((tp)/(tp + fp))\n",
    "    \n",
    "    if (tp + fn) != 0:\n",
    "        recall = ((tp)/(tp + fn))\n",
    "    else:\n",
    "        recall = 0\n",
    "    \n",
    "    # error handling for dividing by 0\n",
    "    if (fp + tn) != 0:\n",
    "        fpr = ((fp) / (fp + tn))\n",
    "    else:\n",
    "        # not confident that this is the best solution, but it seems like 1 would be the worst possible fpr\n",
    "        fpr = 1 \n",
    "    \n",
    "    if (precision + recall) != 0:\n",
    "        f1 = 2 *((precision * recall) / (precision + recall))\n",
    "    else:\n",
    "        f1 = 0\n",
    "    \n",
    "    return precision, recall, fpr, f1\n",
    "\n",
    "def findCCIndexInFile(file_path):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    A function that is used to print the titles for each index in the JSON file from the new algorithm\n",
    "    \n",
    "    Input:\n",
    "        file_path: Path to the JSON file\n",
    "    '''\n",
    "    \n",
    "    file = loadJsonFile(file_path)\n",
    "    for i in range(len(file['story_vectors'])):\n",
    "        print(i)\n",
    "        print(file['story_vectors'][i]['titles'])\n",
    "        \n",
    "def FindBestCCIndex(file_path, story_id):\n",
    "    '''\n",
    "    Function to identify the cc index that yields the best f1 score\n",
    "    \n",
    "    Inputs:\n",
    "        file_path\n",
    "        story_id\n",
    "    Outputs:\n",
    "        best_cc_index\n",
    "        best_f1\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    story_data = loadJsonFile(file_path)\n",
    "    num_ccs = len(story_data['story_vectors'])\n",
    "    \n",
    "    best_f1 = 0\n",
    "    best_cc_index = 0\n",
    "    \n",
    "    for i in range(num_ccs):\n",
    "        precision, recall, fpr, f1 = SingleFileAnalysis(file_path, story_id, i)\n",
    "        if f1 >= best_f1:\n",
    "            best_f1 = f1\n",
    "            best_cc_index = i\n",
    "    return best_cc_index, best_f1\n",
    "\n",
    "def GetCCIndexFileValuesList(story_id, dimension_values):\n",
    "    '''\n",
    "    Function to generate the best cc_index_in_file_values list\n",
    "    \n",
    "    Inputs:\n",
    "        story_id\n",
    "        dimension_vaules: list of dimension values to be tested\n",
    "        \n",
    "    Output:\n",
    "        cc_index_in_file_values: A list of indicies that give the best f1 score for each dimension value\n",
    "    '''\n",
    "    \n",
    "    cc_index_in_file_values = []\n",
    "    \n",
    "    for i in dimension_values:\n",
    "        best_cc_index, best_f1 = FindBestCCIndex(f'data/new_algorithm_files/story_{story_id}/story_{story_id}_dimension_{i}.json', story_id)\n",
    "        cc_index_in_file_values.append(best_cc_index)\n",
    "        \n",
    "    return cc_index_in_file_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f152eb6e-3e1c-4838-8d06-c70c40697154",
   "metadata": {},
   "source": [
    "## Analyzing Different Dimension Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52cf12c6-7171-448f-8db3-f887fd25bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_data = []\n",
    "\n",
    "# Setup the dimension values to cycle through the files and pair with the indices\n",
    "dimension_values = [10, 50, 100, 500, 1000, 1500, 2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8779b0-c54d-4781-9ef3-0a84ff1312a3",
   "metadata": {},
   "source": [
    "### Story 0: Kim/Trump Summit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8885f43-10e7-4c9f-a67a-85c8a8e9a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_index_in_file_values = GetCCIndexFileValuesList(0, dimension_values)\n",
    "TotalStoryAnalysis(0, cc_index_in_file_values, dimension_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b7e970-20da-4dd3-8365-88266082b31d",
   "metadata": {},
   "source": [
    "### Story 1: Senate 2 year 2018 Spending Deal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a8d9f13-2e19-4a16-b891-626a401b57bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_index_in_file_values = GetCCIndexFileValuesList(1, dimension_values)\n",
    "TotalStoryAnalysis(1, cc_index_in_file_values, dimension_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0792a4-5455-4c00-89b8-854d10e97223",
   "metadata": {},
   "source": [
    "### Story 2: Scott Pruitt Resigns as EPA Chief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b84eff-7357-4e63-9149-cfa84c30c8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_index_in_file_values = GetCCIndexFileValuesList(2, dimension_values)\n",
    "TotalStoryAnalysis(2, cc_index_in_file_values, dimension_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbed17f-9472-443f-a404-1647ab5e4fd8",
   "metadata": {},
   "source": [
    "### Story 3: Pittsburgh Synagogue Shooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be55f873-a48b-40e9-af13-36fc11317311",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_index_in_file_values = GetCCIndexFileValuesList(3, dimension_values)\n",
    "TotalStoryAnalysis(3, cc_index_in_file_values, dimension_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcd840a-f12a-495c-a7e7-b01d0648e57b",
   "metadata": {},
   "source": [
    "### Story 4: Senate Votes to End Support for Yemen War"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f2733b9-9e99-45d3-9581-9f94b722bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_index_in_file_values = GetCCIndexFileValuesList(4, dimension_values)\n",
    "TotalStoryAnalysis(4, cc_index_in_file_values, dimension_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde9a9eb-292d-45cc-9be2-6289f16cd5b7",
   "metadata": {},
   "source": [
    "### Story 5: George Bush Dies at 94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e83e2a8-51ee-48e8-a234-af9fb361ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_index_in_file_values = GetCCIndexFileValuesList(5, dimension_values)\n",
    "TotalStoryAnalysis(5, cc_index_in_file_values, dimension_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0069b9-da6f-476b-b30c-7502a61d01b8",
   "metadata": {},
   "source": [
    "### Story 8: Aurora Illinois Shooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb8f7fed-4ef9-407c-acbe-0f9bd7e56080",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_index_in_file_values = GetCCIndexFileValuesList(8, dimension_values)\n",
    "TotalStoryAnalysis(8, cc_index_in_file_values, dimension_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd64b69-d621-4d3b-8659-3d5d11c9a4cc",
   "metadata": {},
   "source": [
    "### Story 9: AOC Town Hall Green New Deal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c5a39bb-f78e-4c24-8a8e-e97711348817",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_index_in_file_values = GetCCIndexFileValuesList(9, dimension_values)\n",
    "TotalStoryAnalysis(9, cc_index_in_file_values, dimension_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b3764f-95f3-4873-91da-622953c9d01c",
   "metadata": {},
   "source": [
    "### Story 11: John Lewis Has Pancreatic Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c51a3b0-0621-4bc6-94c1-504e6b4b3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_index_in_file_values = GetCCIndexFileValuesList(11, dimension_values)\n",
    "TotalStoryAnalysis(11, cc_index_in_file_values, dimension_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c8bab-2537-423c-9d21-f0b2830502cc",
   "metadata": {},
   "source": [
    "### Story 16: Trump Signs Covid Relief Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92bc0641-7537-4d26-b84b-c869d7173218",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_index_in_file_values = GetCCIndexFileValuesList(16, dimension_values)\n",
    "TotalStoryAnalysis(16, cc_index_in_file_values, dimension_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76571b74-9c55-4c42-be04-25628b1b2439",
   "metadata": {},
   "source": [
    "### Story 17: John Lewis Dies at 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a23fb5c7-2c76-418d-a2e3-26527dbd14d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_index_in_file_values = GetCCIndexFileValuesList(17, dimension_values)\n",
    "TotalStoryAnalysis(17, cc_index_in_file_values, dimension_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb97224-938b-43ab-831f-5946d651c572",
   "metadata": {},
   "source": [
    "### Story 19: ASAP Rocky Found Guilty in Sweeden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "481d7391-c53f-45c0-b8d6-95f53313cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_index_in_file_values = GetCCIndexFileValuesList(19, dimension_values)\n",
    "TotalStoryAnalysis(19, cc_index_in_file_values, dimension_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40b0d38b-e011-4bd4-954a-427cc976e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "file = open('new_algorithm_dimension_results.csv', 'w')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow(['story_id', 'dimension_value', 'precision', 'recall', 'fpr', 'f1'])\n",
    "\n",
    "for dictionary in saved_data:\n",
    "    writer.writerow(dictionary.values())\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3c2142-60e6-4fba-891e-93e358a65a79",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f114555a-9bdb-4935-b7e4-6518e021c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def FormatDimensionTables(file_path, metric, output = False):\n",
    "    \n",
    "    data = pd.read_csv(file_path)\n",
    "    new_results_table = pd.DataFrame(columns = (['dimension_value'] + data['story_id'].unique().tolist() + ['average']))\n",
    "    \n",
    "    # list of unique dimension values\n",
    "    dimension_value = data['dimension_value'].unique()\n",
    "\n",
    "    for dimension in dimension_values:\n",
    "    \n",
    "        # selecting where in the dataframe that cutoff is\n",
    "        idx = data['dimension_value'] == dimension\n",
    "        dimension_df = data[idx]\n",
    "\n",
    "        # getting the scores in a list\n",
    "        scores = dimension_df[metric].tolist()\n",
    "        avg = np.average(scores)\n",
    "        row = [dimension] + scores + [avg]\n",
    "\n",
    "        # appending results to the dataframe\n",
    "        new_results_table.loc[len(new_results_table.index)] = row\n",
    "        \n",
    "    new_results_table.to_csv('tables/new_algorithm_' + metric + '_by_dimension.csv', index = False)\n",
    "    \n",
    "    if output == True:\n",
    "        return new_results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c34014-62bc-4c53-bd29-3988e7bf38a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FormatDimensionTables('new_algorithm_dimension_results.csv', 'f1')\n",
    "FormatDimensionTables('new_algorithm_dimension_results.csv', 'precision')\n",
    "FormatDimensionTables('new_algorithm_dimension_results.csv', 'recall')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
