{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b835b283-2469-4faf-9d24-8aa55574492e",
   "metadata": {},
   "source": [
    "## Analysis of the Storygraph Bot Algorithm Compared to the Exemplar Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef2c9f1-b4b0-448e-a288-1d4437da2be6",
   "metadata": {},
   "source": [
    "### Necessary Functions for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc21c62-84dd-4acb-9c9e-89c4363aa9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Imports\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def getUniqueGraphs(story):\n",
    "    '''\n",
    "    This function returns the unique graphs from the story graph bot file as a list of dictionaries. The main goal is to remove any duplicate graphs.\n",
    "    \n",
    "    inputs:\n",
    "        story: A json file from the storygraphbot output of the story.\n",
    "    \n",
    "    output:\n",
    "        unique_graphs: A list of dictionaries that each represent a graph.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #selecting the graphs from the json file from storygraphbot\n",
    "    graph_ids = story['graph_ids']\n",
    "    \n",
    "    #grathering the additional graphs in the reported_graphs section of the storygraphbot json\n",
    "    reported_graphs = story['reported_graphs']\n",
    "    \n",
    "    #combing the graphs from the graph_ids and reported_graphs section\n",
    "    story_union = graph_ids + reported_graphs\n",
    "    \n",
    "    #creating empty lists to append to\n",
    "    unique_graphs = []\n",
    "    unique_graph_ids = []\n",
    "    \n",
    "    \n",
    "    for graph in story_union:\n",
    "        \n",
    "        #checking if the id has been seen before \n",
    "        if graph['id'] not in unique_graph_ids:\n",
    "            \n",
    "            #append the graph and id to the lists\n",
    "            unique_graphs.append(graph)\n",
    "            unique_graph_ids.append(graph['id'])\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return unique_graphs\n",
    "\n",
    "def getFormattedBotGraphs(unique_graphs):\n",
    "    '''\n",
    "    A function that transforms the storygraph bot format to the exemplar format for direct comparison\n",
    "    \n",
    "    inputs:\n",
    "        unique_graphs: A list of dictionaries that each represent a graph in the storygraphbot format.\n",
    "        \n",
    "    outputs:\n",
    "        bot_graphs: A list of dictionaries that each represent a graph in the exemplar format.\n",
    "    '''\n",
    "    \n",
    "    # list to append the dictionary to\n",
    "    bot_graphs = []\n",
    "    \n",
    "    for graph in unique_graphs:\n",
    "        # creating a dictionary for the new formating\n",
    "        graph_dic = {'graph_link': '', 'cc_degree': ''} \n",
    "        \n",
    "        # transforming the graph link from the internet archive format to the csu format\n",
    "        graph_dic['graph_link'] = graph['graph_uri'].replace('https://web.archive.org/storygraph/graphs/usa/', 'https://storygraph.cs.odu.edu/graphs/polar-media-consensus-graph/').replace('hist=144', 'hist=1440')\n",
    "        \n",
    "        # storing the connected component degree\n",
    "        graph_dic['cc_degree'] = graph['avg_degree'] \n",
    "        \n",
    "        # storing the uri with the most edges in the connected component\n",
    "        graph_dic['max_node_link'] = graph['max_node_link'] \n",
    "        \n",
    "        bot_graphs.append(graph_dic)\n",
    "        \n",
    "    return bot_graphs\n",
    "\n",
    "def defineConfusionMatrix(bot_graphs, exemplar_links, want_failed_bots = False):\n",
    "    '''\n",
    "    Function to calculate the True Positive (tp), False Positive (fp), and False Negative (fn) values.\n",
    "    \n",
    "    inputs:\n",
    "        bot_graphs: A list of dictionaries that represent each graph. The ouput of getUniqueGraphs().\n",
    "        exemplar_links: A list of dictionaries that represent each graph. The ouput of getFormattedBotGraphs().\n",
    "    \n",
    "    returns: \n",
    "        tp: an integer for the true positives\n",
    "        fp: an integer for the false positives\n",
    "        fn: an integer for the false negatives\n",
    "        bot_failed_attempts: a list of dictionaries for each graph not found in the exemplar data set\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    #creating a list of the links found in the exemplar dataset\n",
    "    exemplar_link_list = [i['graph_link'] for i in exemplar_links]\n",
    "    \n",
    "    # list to identify any failed attempts\n",
    "    bot_failed_attempts = [] \n",
    "    \n",
    "    # setting values for the true positives, false positives, and false negatives\n",
    "    tp = 0   \n",
    "    fp = 0 \n",
    "    fn = 0 \n",
    "    \n",
    "    \n",
    "    for graph in bot_graphs:\n",
    "        \n",
    "        # looking at each uri from the storygraphbot ouput and seeing that it is in the exemplar data set\n",
    "        if graph['graph_link'] in exemplar_link_list:\n",
    "            \n",
    "            # finding the index where the uri is found in the exemplar data set\n",
    "            idx = exemplar_link_list.index(graph['graph_link']) \n",
    "            \n",
    "            # checking that the degrees of the connected components match where the uri of each matched\n",
    "            # the degree of the storygraphbot output is rounded to 2 decimals because it is a long decimal while\n",
    "            # the exemplar is only 2 digits\n",
    "            \n",
    "            if (round(graph['cc_degree'], 2)) == (exemplar_links[idx]['cc_degree']): \n",
    "                \n",
    "                tp += 1\n",
    "\n",
    "            else:\n",
    "                \n",
    "                # adding to false postive when the storygraphbot output has the correct graph uri but the wrong connected component degree\n",
    "                fp += 1\n",
    "                bot_failed_attempts.append(graph)\n",
    "       \n",
    "        else:\n",
    "            # adding to the false positive when the storygraphbot ouput uri is not found in the exemplar\n",
    "            fp += 1\n",
    "            bot_failed_attempts.append(graph)\n",
    "    \n",
    "    # bot links is a link of uri's ouputed by the storygraphbot algoirthm\n",
    "    bot_links = [bot_graphs[i]['graph_link'] for i in range(len(bot_graphs))]\n",
    "    \n",
    "    #looking at each link in the exemplar links\n",
    "    for link in exemplar_link_list:\n",
    "        \n",
    "        if link not in bot_links:\n",
    "            # adding to the false negative because a link in the exemplar is not found in the storygraphbot output\n",
    "            fn += 1    \n",
    "    if want_failed_bots == True:\n",
    "        return tp, fp, fn, bot_failed_attempts\n",
    "    else:\n",
    "        return tp, fp, fn\n",
    "\n",
    "def getScores(tp, tn, fp, fn):\n",
    "    '''\n",
    "    tp = True Positive\n",
    "    tn = True Negative\n",
    "    fp = False Positive\n",
    "    fn = False Negatives\n",
    "    \n",
    "    return: percision, recall, f1-score\n",
    "    '''\n",
    "    # calculating the precision, recall, and f1-score\n",
    "    \n",
    "    precision = ((tp)/(tp + fp))\n",
    "    recall = ((tp)/(tp+fn))\n",
    "    fpr = ((fp) / (fp + tn))\n",
    "    \n",
    "    f1 = 2 *((precision * recall) / (precision + recall))\n",
    "    \n",
    "    return precision, recall, fpr, f1\n",
    "\n",
    "def getExemplarLinks(story_index):\n",
    "    '''\n",
    "    A function to get the links to each graph for a story in the exemplar data set\n",
    "    \n",
    "    inputs:\n",
    "        story_index: Integer representation of which index the story is in the exemplar data set\n",
    "        \n",
    "    outputs:\n",
    "        exemplar_links: A list of strings where each link is a uri for a graph in the given story\n",
    "    '''\n",
    "    f = open('data/exemplar_dataset.json')\n",
    "    exemplar = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    exemplar_links = exemplar[story_index]['links']\n",
    "    \n",
    "    return exemplar_links\n",
    "\n",
    "def LoadSgbotJson(story_index, date):\n",
    "    '''\n",
    "    Returns the sgbot information for the given story index and date\n",
    "    \n",
    "    Inputs:\n",
    "        story_index: Integer index for the story\n",
    "        date: String representation of the date in the format 'YYYY-MM-DD'\n",
    "    '''\n",
    "    \n",
    "    f = open(f'data/toolkit_files/sgbot_{story_index}/cache/cache_{date}.json', encoding = 'UTF-8')\n",
    "    sgbot = json.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    return sgbot\n",
    "\n",
    "def PerformAnalysis(story_index, date, story_position, print_output = False):\n",
    "    '''\n",
    "    A function to perform an analyis. This is only usable when the story is contained in a json file for one day. Multi-day stories must be done differently.\n",
    "    \n",
    "    inputs:\n",
    "        story_index: Integer index of the story you want to analyze. This index is the position of where it is found in the exemplar data set starting at 0.\n",
    "        date: List of strings of the date of the storygraphbot in the format 'YYYY-MM-DD'. The date is used to pull the json from the storygraphbot output.\n",
    "        story_position: List of integers for the location of where the story can be found in the storygraphbot output. Found by looking for the story in graph_ids.\n",
    "        print_output: Boolean to decide if the precision and recall are printed.\n",
    "    \n",
    "    returns:\n",
    "        precision: float output representing the precision for the algorithm\n",
    "        recall: float output representing the recall for the algorithm\n",
    "        fpr: False Positive Rate\n",
    "        f1: float output representing the f1-score for the algorithm\n",
    "    '''\n",
    "    \n",
    "    ## loading in the toolkit json files\n",
    "    \n",
    "    unique_graphs = []\n",
    "    \n",
    "    if len(story_position) == len(date):\n",
    "        for i in range(len(story_position)):\n",
    "            \n",
    "            sgbot = LoadSgbotJson(story_index, date[i])\n",
    "    \n",
    "            story = sgbot[date[i]]['stories'][story_position[i]]\n",
    "            unique_graph_part = getUniqueGraphs(story)\n",
    "            \n",
    "            unique_graphs += unique_graph_part\n",
    "    else:\n",
    "        print('Lengths of story_position and date lists are not equal')\n",
    "    \n",
    "    bot_graphs = getFormattedBotGraphs(unique_graphs)\n",
    "    \n",
    "    exemplar_links = getExemplarLinks(story_index)\n",
    "    \n",
    "    tp, fp, fn = defineConfusionMatrix(bot_graphs, exemplar_links)\n",
    "    \n",
    "    tn = defineTrueNegatives(story_index, date, story_position, exemplar_links)\n",
    "    \n",
    "    precision, recall, fpr, f1 = getScores(tp, tn, fp, fn)\n",
    "    \n",
    "    if print_output == True:\n",
    "        print(f'Story {story_index} Output')\n",
    "        print(f'percision: {precision}\\nrecall: {recall}\\nf1-score: {f1}')\n",
    "    \n",
    "    return precision, recall, fpr, f1\n",
    "\n",
    "def defineTrueNegatives(story_index, date, story_position, exemplar_links):\n",
    "    \n",
    "    '''\n",
    "    A function calculate the amount of true negatives.\n",
    "    \n",
    "    Inputs:\n",
    "        story_index: An integer representation of the story\n",
    "        date: A list of strings, each a date in the format 'YYYY-MM-DD'\n",
    "        story_position: A list of integers that represent the index where the desired story is found\n",
    "        exemplar_links: A list of dictionaries that each represent a connected component in the exemplar dataset\n",
    "    '''\n",
    "    \n",
    "    tn = 0\n",
    "\n",
    "    #creating a list of the links found in the exemplar dataset\n",
    "    exemplar_link_list = [i['graph_link'] for i in exemplar_links]\n",
    "\n",
    "    unique_non_selected_ccs = []\n",
    "    for i in range(len(story_position)):\n",
    "        \n",
    "        ## load in the information for that day from the json file\n",
    "        sgbot = LoadSgbotJson(story_index, date[i]) \n",
    "\n",
    "        non_selected_stories = sgbot[date[i]]['stories'][:story_position[i]] + sgbot[date[i]]['stories'][story_position[i]+1:]\n",
    "\n",
    "        for i in range(len(non_selected_stories)):\n",
    "            unique_non_selected_stories = getUniqueGraphs(non_selected_stories[i])\n",
    "            unique_non_selected_ccs += unique_non_selected_stories\n",
    "\n",
    "    formated_bot_graphs = getFormattedBotGraphs(unique_non_selected_ccs)\n",
    "\n",
    "    for graph in formated_bot_graphs:\n",
    "    \n",
    "        # if the graph link is not found in the exemplar, then it is a true negative\n",
    "        if graph['graph_link'] not in exemplar_link_list:\n",
    "        \n",
    "            tn += 1\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            # find where the link matches\n",
    "            idx = exemplar_link_list.index(graph['graph_link']) \n",
    "        \n",
    "            # don't have the index for the old algorithm, only the cc_degree. If the degrees don't match up, then it is a true negative.\n",
    "            if (round(graph['cc_degree'], 2)) != (exemplar_links[idx]['cc_degree']): \n",
    "                \n",
    "                        tn += 1\n",
    "    return tn\n",
    "\n",
    "# these functions below (getGraphLinks, getLinksFromJson) are still in development and not necessary for the current algorithm evaluation\n",
    "\n",
    "def getGraphLinks(input_file, index):\n",
    "    '''\n",
    "    \n",
    "    A function that pull the json file for each graph.\n",
    "    \n",
    "    inputs:\n",
    "        input_file: A json file that has the storygraphbot output \n",
    "        index: an integer representing the index of where the story is found in the input_file. \n",
    "        \n",
    "    '''\n",
    "    cursor_finder = r'(?<=#cursor=)(\\d*)(?=&hist)'\n",
    "    date_finder = r'(?<=t=)(\\d*-\\d*-\\d*)(?=T)'\n",
    "    cursor = re.search(cursor_finder, input_file[index]['graph_link'])\n",
    "    date = re.search(date_finder, input_file[index]['graph_link'])\n",
    "    year, month, day = date.group().split('-')\n",
    "    index = cursor.group()\n",
    "    \n",
    "    uri = f'https://storygraph.cs.odu.edu/graphs/polar-media-consensus-graph/{year}/{month}/{day}/graph{index}.json'\n",
    "    \n",
    "    graph_data = requests.get(uri)\n",
    "    graph_json = json.loads(graph_data.text)\n",
    "    \n",
    "    return graph_json\n",
    "\n",
    "def getLinksFromJson(input_file, index):\n",
    "    '''\n",
    "    Returns a list of links that make up the connected component\n",
    "    \n",
    "    '''\n",
    "    input_file = getGraphLinks(input_file, index)\n",
    "    cc_nodes = input_file['connected-comps'][0]['nodes']\n",
    "    cc_links = [input_file['nodes'][int(i)-1]['link'] for i in cc_nodes]\n",
    "    \n",
    "    return cc_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48cce05a-0b37-4d74-98e0-a526eb68aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd3255b-be8b-4b15-9eda-ef9716b48c1a",
   "metadata": {},
   "source": [
    "## Story 0: Kim/Trump Summit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a07938-8a68-41c4-80b9-437610b15c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fpr, f1 = PerformAnalysis(0, ['2018-06-12'], [0])\n",
    "row = {'story_id': 0, 'precision': precision, 'recall': recall, 'fpr': fpr, 'f1': f1} \n",
    "saved_data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff962ec0-8071-4b55-97bf-6993bdaa1977",
   "metadata": {},
   "source": [
    "## Story 1: Senate 2 year 2018 Spending Deal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f642b7-4bc2-46a2-81c7-8fa17432ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fpr, f1 = PerformAnalysis(1, ['2018-02-07'], [1])\n",
    "row = {'story_id': 1, 'precision': precision, 'recall': recall, 'fpr': fpr, 'f1': f1} \n",
    "saved_data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1846621a-cf7e-4266-b607-7718a5903d8a",
   "metadata": {},
   "source": [
    "## Story 2: Scott Pruitt Resigns as EPA Chief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "860d3ff3-e1d8-4bbe-8382-0faaa986775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fpr, f1 = PerformAnalysis(2, ['2018-07-05'], [0])\n",
    "row = {'story_id': 2, 'precision': precision, 'recall': recall, 'fpr': fpr, 'f1': f1} \n",
    "saved_data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d050daa3-6153-4d1b-a997-ae70dc38b376",
   "metadata": {},
   "source": [
    "## Story 3: Pittsburgh Synagogue Shooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f235bc9-079e-40e4-a207-1e82b4c98322",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fpr, f1 = PerformAnalysis(3, ['2018-10-28', '2018-10-29'], [0, 4])\n",
    "row = {'story_id': 3, 'precision': precision, 'recall': recall, 'fpr': fpr, 'f1': f1} \n",
    "saved_data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d45c909-4eec-4524-a526-ade848322ca4",
   "metadata": {},
   "source": [
    "## Story 4: Senate Votes to End Support for Yemen War"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52be333b-bb59-4129-8531-9808935b3a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Story did not appear in the sgbot output, may be too small of a story to have registered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eed5db1-013a-44a3-8bac-733e25f8d100",
   "metadata": {},
   "source": [
    "## Story 5: George Bush Dies at 94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70856163-d798-4e46-8239-64082469bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fpr, f1 = PerformAnalysis(5, ['2018-12-01', '2018-12-02'], [0, 0])\n",
    "row = {'story_id': 5, 'precision': precision, 'recall': recall, 'fpr': fpr, 'f1': f1} \n",
    "saved_data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5474890-5f01-4757-9870-be3c0219ede9",
   "metadata": {},
   "source": [
    "## Story 8: Aurora Illinois Shooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec72e8aa-f4ee-44a6-9a22-2c6b6a31a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fpr, f1 = PerformAnalysis(8, ['2019-02-16'], [0])\n",
    "row = {'story_id': 8, 'precision': precision, 'recall': recall, 'fpr': fpr, 'f1': f1} \n",
    "saved_data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d208082-2cf3-4704-ac7b-5155fa615cc3",
   "metadata": {},
   "source": [
    "## Story 9: AOC Town Hall Green New Deal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40339f6e-244c-4caf-80ad-96e2acb36957",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fpr, f1 = PerformAnalysis(9, ['2019-03-30'], [0])\n",
    "row = {'story_id': 9, 'precision': precision, 'recall': recall, 'fpr': fpr, 'f1': f1} \n",
    "saved_data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce14b083-d731-4ad7-8be6-524a8a628adc",
   "metadata": {},
   "source": [
    "## Story 11: John Lewis Has Pancreatic Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0390170-badc-4d08-927d-f81ae11fe0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storygraph bot gave no output for this story even after hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b07d72-7a0e-409c-b021-d39f21c88980",
   "metadata": {},
   "source": [
    "## Story 16: Trump Signs Covid Relief Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deda86df-db9b-4abc-8f2c-05448303a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fpr, f1 = PerformAnalysis(16, ['2020-12-28'], [0])\n",
    "row = {'story_id': 16, 'precision': precision, 'recall': recall, 'fpr': fpr, 'f1': f1} \n",
    "saved_data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5b7b0e-9217-46d3-a0da-4e613afe15d2",
   "metadata": {},
   "source": [
    "## Story 17: John Lewis Dies at 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a396546-e4d3-48d6-8444-31b560e5a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fpr, f1 = PerformAnalysis(17, ['2020-07-18', '2020-07-19'], [0, 0])\n",
    "row = {'story_id': 17, 'precision': precision, 'recall': recall, 'fpr': fpr, 'f1': f1} \n",
    "saved_data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639e15a5-9ac9-4624-9d1c-ab9748c8d6fa",
   "metadata": {},
   "source": [
    "## Story 19: ASAP Rocky Found Guilty in Sweeden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "563d8512-79c6-456f-82c1-2cc05dda708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fpr, f1 = PerformAnalysis(19, ['2019-08-14'], [0])\n",
    "row = {'story_id': 19, 'precision': precision, 'recall': recall, 'fpr': fpr, 'f1': f1} \n",
    "saved_data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e279ffde-8af4-4855-ae63-99fe79d93347",
   "metadata": {},
   "source": [
    "### Saving the Data as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30a554fc-f5bb-4576-90c2-e0520904caea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "file = open('current_algorithm_results_with_fpr.csv', 'w')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow(['story_id', 'precision', 'recall', 'fpr', 'f1'])\n",
    "\n",
    "for dictionary in saved_data:\n",
    "    writer.writerow(dictionary.values())\n",
    "    \n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
