{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa162070-94aa-4d5b-8b9c-18dd42f68360",
   "metadata": {},
   "source": [
    "# Functions for Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "e11a16f9-06f6-4921-b937-a3734f42932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Imports\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def getUniqueGraphs(story):\n",
    "    '''\n",
    "    This function returns the unique graphs from the story graph bot file as a list of dictionaries. The main goal is to remove any duplicate graphs.\n",
    "    \n",
    "    inputs:\n",
    "        story: A json file from the storygraphbot output of the story.\n",
    "    \n",
    "    output:\n",
    "        unique_graphs: A list of dictionaries that each represent a graph.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #selecting the graphs from the json file from storygraphbot\n",
    "    graph_ids = story['graph_ids']\n",
    "    \n",
    "    #grathering the additional graphs in the reported_graphs section of the storygraphbot json\n",
    "    reported_graphs = story['reported_graphs']\n",
    "    \n",
    "    #combing the graphs from the graph_ids and reported_graphs section\n",
    "    story_union = graph_ids + reported_graphs\n",
    "    \n",
    "    #creating empty lists to append to\n",
    "    unique_graphs = []\n",
    "    unique_graph_ids = []\n",
    "    \n",
    "    \n",
    "    for graph in story_union:\n",
    "        \n",
    "        #checking if the id has been seen before \n",
    "        if graph['id'] not in unique_graph_ids:\n",
    "            \n",
    "            #append the graph and id to the lists\n",
    "            unique_graphs.append(graph)\n",
    "            unique_graph_ids.append(graph['id'])\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return unique_graphs\n",
    "\n",
    "def getFormattedBotGraphs(unique_graphs):\n",
    "    '''\n",
    "    A function that transforms the storygraph bot format to the exemplar format for direct comparison\n",
    "    \n",
    "    inputs:\n",
    "        unique_graphs: A list of dictionaries that each represent a graph in the storygraphbot format.\n",
    "        \n",
    "    outputs:\n",
    "        bot_graphs: A list of dictionaries that each represent a graph in the exemplar format.\n",
    "    '''\n",
    "    \n",
    "    # list to append the dictionary to\n",
    "    bot_graphs = []\n",
    "    \n",
    "    for graph in unique_graphs:\n",
    "        # creating a dictionary for the new formating\n",
    "        graph_dic = {'graph_link': '', 'cc_degree': ''} \n",
    "        \n",
    "        # transforming the graph link from the internet archive format to the csu format\n",
    "        graph_dic['graph_link'] = graph['graph_uri'].replace('https://web.archive.org/storygraph/graphs/usa/', 'https://storygraph.cs.odu.edu/graphs/polar-media-consensus-graph/').replace('hist=144', 'hist=1440')\n",
    "        \n",
    "        # storing the connected component degree\n",
    "        graph_dic['cc_degree'] = graph['avg_degree'] \n",
    "        \n",
    "        # storing the uri with the most edges in the connected component\n",
    "        graph_dic['max_node_link'] = graph['max_node_link'] \n",
    "        \n",
    "        bot_graphs.append(graph_dic)\n",
    "        \n",
    "    return bot_graphs\n",
    "\n",
    "def defineConfusionMatrix(bot_graphs, exemplar_links, want_failed_bots = False):\n",
    "    '''\n",
    "    Function to calculate the True Positive (tp), False Positive (fp), and False Negative (fn) values.\n",
    "    \n",
    "    inputs:\n",
    "        bot_graphs: A list of dictionaries that represent each graph. The ouput of getUniqueGraphs().\n",
    "        exemplar_links: A list of dictionaries that represent each graph. The ouput of getFormattedBotGraphs().\n",
    "    \n",
    "    returns: \n",
    "        tp: an integer for the true positives\n",
    "        fp: an integer for the false positives\n",
    "        fn: an integer for the false negatives\n",
    "        bot_failed_attempts: a list of dictionaries for each graph not found in the exemplar data set\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    #creating a list of the links found in the exemplar dataset\n",
    "    exemplar_link_list = [i['graph_link'] for i in exemplar_links]\n",
    "    \n",
    "    # list to identify any failed attempts\n",
    "    bot_failed_attempts = [] \n",
    "    \n",
    "    # setting values for the true positives, false positives, and false negatives\n",
    "    tp = 0   \n",
    "    fp = 0 \n",
    "    fn = 0 \n",
    "    \n",
    "    \n",
    "    for graph in bot_graphs:\n",
    "        \n",
    "        # looking at each uri from the storygraphbot ouput and seeing that it is in the exemplar data set\n",
    "        if graph['graph_link'] in exemplar_link_list:\n",
    "            \n",
    "            # finding the index where the uri is found in the exemplar data set\n",
    "            idx = exemplar_link_list.index(graph['graph_link']) \n",
    "            \n",
    "            # checking that the degrees of the connected components match where the uri of each matched\n",
    "            # the degree of the storygraphbot output is rounded to 2 decimals because it is a long decimal while\n",
    "            # the exemplar is only 2 digits\n",
    "            \n",
    "            if (round(graph['cc_degree'], 2)) == (exemplar_links[idx]['cc_degree']): \n",
    "                \n",
    "                tp += 1\n",
    "\n",
    "            else:\n",
    "                \n",
    "                # adding to false postive when the storygraphbot output has the correct graph uri but the wrong connected component degree\n",
    "                fp += 1\n",
    "                bot_failed_attempts.append(graph)\n",
    "       \n",
    "        else:\n",
    "            # adding to the false positive when the storygraphbot ouput uri is not found in the exemplar\n",
    "            fp += 1\n",
    "            bot_failed_attempts.append(graph)\n",
    "    \n",
    "    # bot links is a link of uri's ouputed by the storygraphbot algoirthm\n",
    "    bot_links = [bot_graphs[i]['graph_link'] for i in range(len(bot_graphs))]\n",
    "    \n",
    "    #looking at each link in the exemplar links\n",
    "    for link in exemplar_link_list:\n",
    "        \n",
    "        if link not in bot_links:\n",
    "            # adding to the false negative because a link in the exemplar is not found in the storygraphbot output\n",
    "            fn += 1    \n",
    "    if want_failed_bots == True:\n",
    "        return tp, fp, fn, bot_failed_attempts\n",
    "    else:\n",
    "        return tp, fp, fn\n",
    "\n",
    "def getScores(tp, fp, fn):\n",
    "    '''\n",
    "    tp = True Positive\n",
    "    fp = False Positive\n",
    "    fn = False Negatives\n",
    "    \n",
    "    return: percision, recall, f1-score\n",
    "    '''\n",
    "    # calculating the precision, recall, and f1-score\n",
    "    \n",
    "    precision = ((tp)/(tp + fp))\n",
    "    recall = ((tp)/(tp+fn))\n",
    "    f1 = 2 *((precision * recall) / (precision + recall))\n",
    "    return precision, recall, f1\n",
    "\n",
    "def getExemplarLinks(story_index):\n",
    "    '''\n",
    "    A function to get the links to each graph for a story in the exemplar data set\n",
    "    \n",
    "    inputs:\n",
    "        story_index: Integer representation of which index the story is in the exemplar data set\n",
    "        \n",
    "    outputs:\n",
    "        exemplar_links: A list of strings where each link is a uri for a graph in the given story\n",
    "    '''\n",
    "    f = open('data/exemplar_dataset.json')\n",
    "    exemplar = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    exemplar_links = exemplar[story_index]['links']\n",
    "    \n",
    "    return exemplar_links\n",
    "\n",
    "def PerformAnalysis(story_index, date, story_position, print_output = False):\n",
    "    '''\n",
    "    A function to perform an analyis. This is only usable when the story is contained in a json file for one day. Multi-day stories must be done differently.\n",
    "    \n",
    "    inputs:\n",
    "        story_index: Integer index of the story you want to analyze. This index is the position of where it is found in the exemplar data set starting at 0.\n",
    "        date: String of the date of the storygraphbot in the format 'YYYY-MM-DD'. The date is used to pull the json from the storygraphbot output.\n",
    "        story_position: Integer for th location of where the story can be found in the storygraphbot output. Found by looking for the story in graph_ids.\n",
    "        print_output: Boolean to decide if the precision and recall are printed.\n",
    "    \n",
    "    returns:\n",
    "        precision: float output representing the precision for the algorithm\n",
    "        recall: float output representing the recall for the algorithm\n",
    "        f1: float output representing the f1-score for the algorithm\n",
    "    '''\n",
    "    \n",
    "    f = open(f'data/toolkit_files/sgbot_{story_index}/cache/cache_{date}.json', encoding = 'UTF-8')\n",
    "    sgbot = json.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    story = sgbot[date]['stories'][story_position]\n",
    "    unique_graphs = getUniqueGraphs(story)\n",
    "    bot_graphs = getFormattedBotGraphs(unique_graphs)\n",
    "    \n",
    "    exemplar_links = getExemplarLinks(story_index)\n",
    "    \n",
    "    tp, fp, fn = defineConfusionMatrix(bot_graphs, exemplar_links)\n",
    "    precision, recall, f1 = getScores(tp, fp, fn)\n",
    "    \n",
    "    if print_output == True:\n",
    "        print(f'Story {story_index} Output')\n",
    "        print(f'percision: {precision}\\nrecall: {recall}\\nf1-score: {f1}')\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# these functions below (getGraphLinks, getLinksFromJson) are still in development and not necessary for the current algorithm evaluation\n",
    "\n",
    "def getGraphLinks(input_file, index):\n",
    "    '''\n",
    "    \n",
    "    A function that pull the json file for each graph.\n",
    "    \n",
    "    inputs:\n",
    "        input_file: A json file that has the storygraphbot output \n",
    "        index: an integer representing the index of where the story is found in the input_file. \n",
    "        \n",
    "    '''\n",
    "    cursor_finder = r'(?<=#cursor=)(\\d*)(?=&hist)'\n",
    "    date_finder = r'(?<=t=)(\\d*-\\d*-\\d*)(?=T)'\n",
    "    cursor = re.search(cursor_finder, input_file[index]['graph_link'])\n",
    "    date = re.search(date_finder, input_file[index]['graph_link'])\n",
    "    year, month, day = date.group().split('-')\n",
    "    index = cursor.group()\n",
    "    \n",
    "    uri = f'https://storygraph.cs.odu.edu/graphs/polar-media-consensus-graph/{year}/{month}/{day}/graph{index}.json'\n",
    "    \n",
    "    graph_data = requests.get(uri)\n",
    "    graph_json = json.loads(graph_data.text)\n",
    "    \n",
    "    return graph_json\n",
    "\n",
    "def getLinksFromJson(input_file, index):\n",
    "    '''\n",
    "    Returns a list of links that make up the connected component\n",
    "    \n",
    "    '''\n",
    "    input_file = getGraphLinks(input_file, index)\n",
    "    cc_nodes = input_file['connected-comps'][0]['nodes']\n",
    "    cc_links = [input_file['nodes'][int(i)-1]['link'] for i in cc_nodes] # i need to know if the indexing for nodes starts at 0 or 1\n",
    "    \n",
    "    return cc_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5cad0264-c456-49a7-b866-f1995ec83c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing a dataframe to store the scores for each story\n",
    "df = pd.DataFrame(columns = ['Story_Id', 'Story_Name', 'Percision', 'Recall', 'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399572db-f879-4d07-994d-dadb3d4bcfe5",
   "metadata": {},
   "source": [
    "## Story 0\n",
    "\n",
    "#### North Korea Summit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "f1b80778-e8ad-46a2-b84f-5fbb2ee97442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in the storygraphbot dataset\n",
    "f = open('data/toolkit_files/sgbot_0/cache/cache_2018-06-12.json', encoding = 'UTF-8')\n",
    "sgbot_0 = json.load(f)\n",
    "f.close()\n",
    "\n",
    "story = sgbot_0['2018-06-12']['stories'][0]\n",
    "unique_graphs = getUniqueGraphs(story)\n",
    "bot_graphs = getFormattedBotGraphs(unique_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "7e8ff709-d28d-45b3-beaa-1303a21bba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading in the exemplar data\n",
    "f = open('data/exemplar_dataset.json')\n",
    "exemplar = json.load(f)\n",
    "f.close()\n",
    "\n",
    "exemplar_links = exemplar[0]['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "1dee0e06-47d4-4f42-baec-6978de9cee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create confusion matrix and get values\n",
    "tp, fp, fn = defineConfusionMatrix(bot_graphs, exemplar_links)\n",
    "percision, recall, f1 = getScores(tp, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "f4143b42-befc-4d58-b7cb-83c3c33aa2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story 0 Output\n",
      "percision: 0.9902912621359223\n",
      "recall: 0.6257668711656442\n"
     ]
    }
   ],
   "source": [
    "print('Story 0 Output')\n",
    "print(f'percision: {percision}\\nrecall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "1669a2a4-cf5c-43c4-8eb2-85baa79e7eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story 0 Output\n",
      "percision: 0.9902912621359223\n",
      "recall: 0.6257668711656442\n",
      "f1-score: 0.7669172932330828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9902912621359223, 0.6257668711656442, 0.7669172932330828)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PerformAnalysis(0, '2018-06-12', 0, print_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8681cb94-ea35-4eb7-b4d3-bab28a8f3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[len(df)] = [0, 'North Korea Summit', percision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3326fc-8280-41d2-8283-7dadd4b12d2a",
   "metadata": {},
   "source": [
    "## Story 1\n",
    "\n",
    "#### Senate Spending Bill Passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "8211f445-e62b-4338-b65d-2b92ef40a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This story had little to no reported graphs really, not a great one to look at\n",
    "f = open('data/toolkit_files/sgbot_1/cache/cache_2018-02-07.json', encoding = 'UTF-8')\n",
    "sgbot_1 = json.load(f)\n",
    "f.close()\n",
    "\n",
    "story = sgbot_1['2018-02-07']['stories'][1]\n",
    "unique_graphs = getUniqueGraphs(story)\n",
    "bot_graphs = getFormattedBotGraphs(unique_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "276b2318-2a48-4fc5-9282-407bc73416bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/exemplar_dataset.json')\n",
    "exemplar = json.load(f)\n",
    "f.close()\n",
    "\n",
    "exemplar_links = exemplar[1]['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "1dc77d37-c594-4dc7-b1d8-4c8a74bb124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn = defineConfusionMatrix(bot_graphs, exemplar_links)\n",
    "percision, recall, f1 = getScores(tp, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "a8de6a66-be5f-491d-af54-aaaae547ac2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story 1 Output\n",
      "percision: 1.0\n",
      "recall: 0.0392156862745098\n"
     ]
    }
   ],
   "source": [
    "print('Story 1 Output')\n",
    "print(f'percision: {percision}\\nrecall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17906a6e-7ac4-4a1f-ab25-4fa53fcfaa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PerformAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "73f78074-d45c-441d-86e2-90f7daa4479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[len(df)] = [1, 'Senate Spending Bill Passes', percision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd0bf1a-6bc4-4d71-a392-42921dcea73e",
   "metadata": {},
   "source": [
    "## Story 2\n",
    "\n",
    "#### Scott Resigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "56ad67d9-713b-4000-9d56-44de6272aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/toolkit_files/sgbot_2/cache/cache_2018-07-05.json', encoding = 'UTF-8')\n",
    "sgbot_2 = json.load(f)\n",
    "f.close()\n",
    "\n",
    "story = sgbot_2['2018-07-05']['stories'][0]\n",
    "unique_graphs = getUniqueGraphs(story)\n",
    "bot_graphs = getFormattedBotGraphs(unique_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "fa5cd7f9-0eaa-4f86-b9ca-b0a0714438ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/exemplar_dataset.json')\n",
    "exemplar = json.load(f)\n",
    "f.close()\n",
    "\n",
    "exemplar_links = exemplar[2]['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "0ea7bb99-d829-4e4c-b1d8-7b799ba8c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn = defineConfusionMatrix(bot_graphs, exemplar_links)\n",
    "percision, recall, f1 = getScores(tp, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9601b3c0-d102-4ad8-a005-325028fa0c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story 2 Output\n",
      "percision: 0.9523809523809523\n",
      "recall: 0.20833333333333334\n"
     ]
    }
   ],
   "source": [
    "print('Story 2 Output')\n",
    "print(f'percision: {percision}\\nrecall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "85c8f146-37fb-4e2a-904a-c88e62f949a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[len(df)] = [2, 'Scott Pruitt Resigns', percision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230fa60b-5e42-4312-b599-6a0b0f5ed861",
   "metadata": {},
   "source": [
    "## Story 3\n",
    "\n",
    "#### Pittsburgh Synagogue Shooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "316fd7bb-f1b5-48da-aeae-0d809da780b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/toolkit_files/sgbot_3/cache/cache_2018-10-28.json', encoding = 'UTF-8')\n",
    "sgbot_3_day_1 = json.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('data/toolkit_files/sgbot_3/cache/cache_2018-10-29.json', encoding = 'UTF-8')\n",
    "sgbot_3_day_2 = json.load(f)\n",
    "f.close()\n",
    "\n",
    "day_1_graphs = sgbot_3_day_1['2018-10-28']['stories'][0]\n",
    "day_2_graphs = sgbot_3_day_2['2018-10-29']['stories'][4]\n",
    "\n",
    "unique_graphs_1 = getUniqueGraphs(day_1_graphs)\n",
    "unique_graphs_2 = getUniqueGraphs(day_2_graphs)\n",
    "\n",
    "unique_graphs = unique_graphs_1 + unique_graphs_2\n",
    "bot_graphs = getFormattedBotGraphs(unique_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "231c0e63-77a1-4655-bcdc-618864ab01b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/exemplar_dataset.json')\n",
    "exemplar = json.load(f)\n",
    "f.close()\n",
    "\n",
    "exemplar_links = exemplar[3]['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b7e3383b-cf43-4325-ace0-f82aa77f3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn = defineConfusionMatrix(bot_graphs, exemplar_links)\n",
    "percision, recall, f1 = getScores(tp, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "940596b4-1354-4d89-a01a-ba7005d1919b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story 3 Output\n",
      "percision: 0.9642857142857143\n",
      "recall: 0.47703180212014135\n"
     ]
    }
   ],
   "source": [
    "print('Story 3 Output')\n",
    "print(f'percision: {percision}\\nrecall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0d3d3abd-1707-4632-ad0b-585a7916662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[len(df)] = [3, 'Pittsburgh Syngogue Shooting', percision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffdea55-24cc-43ed-bf04-f86b57a90408",
   "metadata": {},
   "source": [
    "## Story 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ef2f1196-1f8d-4d10-a639-1545f35abf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Yemen story didn't appear at all in the story grpah bot data set, maybe it was too small of a story?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0dbf3755-c121-48a2-a3a7-bd49ff84b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[len(df)] = [4, 'Yemen War Bill', 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f6af74-40ea-431e-9e6f-58c952215620",
   "metadata": {},
   "source": [
    "## Story 5\n",
    "\n",
    "#### George Bush Sr Dies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f339f5cd-5b68-4314-94f6-61421b6126ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/toolkit_files/sgbot_5/cache/cache_2018-12-01.json', encoding = 'UTF-8')\n",
    "sgbot_5_day_1 = json.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('data/toolkit_files/sgbot_5/cache/cache_2018-12-02.json', encoding = 'UTF-8')\n",
    "sgbot_5_day_2 = json.load(f)\n",
    "f.close()\n",
    "\n",
    "day_1_graphs = sgbot_5_day_1['2018-12-01']['stories'][0]\n",
    "day_2_graphs = sgbot_5_day_2['2018-12-02']['stories'][0]\n",
    "\n",
    "unique_graphs_1 = getUniqueGraphs(day_1_graphs)\n",
    "unique_graphs_2 = getUniqueGraphs(day_2_graphs)\n",
    "\n",
    "unique_graphs = unique_graphs_1 + unique_graphs_2\n",
    "bot_graphs = getFormattedBotGraphs(unique_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7d03fd05-1b23-435a-8f91-a7022fd45a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplar_links = exemplar[5]['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "20418795-fa4d-43f6-a182-47fcec94a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn = defineConfusionMatrix(bot_graphs, exemplar_links)\n",
    "percision, recall, f1 = getScores(tp, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "aae776e3-c9cb-403e-8746-1e66f7c36239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story 5 Output\n",
      "percision: 0.8625592417061612\n",
      "recall: 0.8310502283105022\n"
     ]
    }
   ],
   "source": [
    "print('Story 5 Output')\n",
    "print(f'percision: {percision}\\nrecall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ab84d479-c101-4624-889f-46384845bc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[len(df)] = [5, 'George Bush Sr Dies', percision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "186042ee-8992-4f7b-85a4-196a7067fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like it did a great job on this one, makes sense since it is a large story"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc079da-3e6c-4b8e-824a-44dee1116d6a",
   "metadata": {},
   "source": [
    "## Story 8\n",
    "\n",
    "#### Aurora Illinois Shooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a4b6d40e-2d8c-4cfc-be78-a0af06d1230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/toolkit_files/sgbot_8/cache/cache_2019-02-16.json', encoding = 'UTF-8')\n",
    "sgbot_8 = json.load(f)\n",
    "f.close()\n",
    "\n",
    "story = sgbot_8['2019-02-16']['stories'][0]\n",
    "unique_graphs = getUniqueGraphs(story)\n",
    "bot_graphs = getFormattedBotGraphs(unique_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a1d93adc-f73c-4021-9d3b-9bd659b0f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplar_links = exemplar[8]['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6dd92adc-8dc8-4734-afbf-7447c2bef1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn = defineConfusionMatrix(bot_graphs, exemplar_links)\n",
    "percision, recall, f1 = getScores(tp, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "439ff531-23f3-492b-a927-10a3759c94e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story 8 Output\n",
      "percision: 1.0\n",
      "recall: 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "print('Story 8 Output')\n",
    "print(f'percision: {percision}\\nrecall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "089bc450-517d-49e4-b889-3039f44f829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[len(df)] = [8, 'Aurora Illinois Shooting', percision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c49d6a6-38b0-4155-b4b2-977feb3db0aa",
   "metadata": {},
   "source": [
    "## Story 9\n",
    "#### Green New Deal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "27ea3932-cf4f-448e-83a1-aa53f9e716af",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/toolkit_files/sgbot_9/cache/cache_2019-03-30.json', encoding = 'UTF-8')\n",
    "sgbot_9 = json.load(f)\n",
    "f.close()\n",
    "\n",
    "story = sgbot_9['2019-03-30']['stories'][0]\n",
    "unique_graphs = getUniqueGraphs(story)\n",
    "bot_graphs = getFormattedBotGraphs(unique_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "af1fc2a0-7bae-472e-8fc3-a56dd7d4d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplar_links = exemplar[9]['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "8a05b662-e023-47a4-8001-02249ce72c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn = defineConfusionMatrix(bot_graphs, exemplar_links)\n",
    "percision, recall, f1 = getScores(tp, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "56c9c91d-d974-4ac7-91d1-84db5b591199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story 9 Output\n",
      "percision: 1.0\n",
      "recall: 0.5348837209302325\n"
     ]
    }
   ],
   "source": [
    "print('Story 9 Output')\n",
    "print(f'percision: {percision}\\nrecall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4f9a8a31-032a-4221-b7f0-69f0e0aedb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[len(df)] = [9, 'Green New Deal', percision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1e883a-6bfc-4d0f-97d1-94351a6c7c1c",
   "metadata": {},
   "source": [
    "## Story 11\n",
    "#### John Lewis has Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7d50d5ba-5b3d-4643-bd9e-7c7f4016ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There was no output from the function for story 11, the function ran for hours without output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce32d92-2670-4b85-a46f-e63b03a6cee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65dad4f4-32a2-4ffb-845d-15e036beb312",
   "metadata": {},
   "source": [
    "## Story 16\n",
    "\n",
    "#### Trump Signs Covid Relief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ea9f5bf5-bc5a-41fe-b173-34fcd9ffd5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/toolkit_files/sgbot_16/cache/cache_2020-12-28.json', encoding = 'UTF-8')\n",
    "sgbot_16 = json.load(f)\n",
    "f.close()\n",
    "\n",
    "story = sgbot_16['2020-12-28']['stories'][0]\n",
    "unique_graphs = getUniqueGraphs(story)\n",
    "bot_graphs = getFormattedBotGraphs(unique_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "063d446c-9624-48a7-beaf-6f22ab60cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplar_links = exemplar[16]['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "96348162-4d7e-4ae8-89dc-3372a0a0640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn = defineConfusionMatrix(bot_graphs, exemplar_links)\n",
    "percision, recall, f1 = getScores(tp, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "71be99ee-335a-4878-95be-d39323c228e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story 16 Output\n",
      "percision: 0.9807692307692307\n",
      "recall: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "print('Story 16 Output')\n",
    "print(f'percision: {percision}\\nrecall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "bdd9956f-3846-4d52-a778-554d1acbfef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[len(df)] = [16, 'Trump Signs Covid Relief', percision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a42c8bd-b617-40b0-8342-556d658171f5",
   "metadata": {},
   "source": [
    "## Story 17\n",
    "#### John Lewis Dies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "d01e6098-645b-42a2-a5ef-7ecb0db7e4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/toolkit_files/sgbot_17/cache/cache_2020-07-18.json', encoding = 'UTF-8')\n",
    "sgbot_17_day_1 = json.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('data/toolkit_files/sgbot_17/cache/cache_2020-07-19.json', encoding = 'UTF-8')\n",
    "sgbot_17_day_2 = json.load(f)\n",
    "f.close()\n",
    "\n",
    "day_1_graphs = sgbot_17_day_1['2020-07-18']['stories'][0]\n",
    "day_2_graphs = sgbot_17_day_2['2020-07-19']['stories'][0]\n",
    "\n",
    "unique_graphs_1 = getUniqueGraphs(day_1_graphs)\n",
    "unique_graphs_2 = getUniqueGraphs(day_2_graphs)\n",
    "\n",
    "unique_graphs = unique_graphs_1 + unique_graphs_2\n",
    "bot_graphs = getFormattedBotGraphs(unique_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "df9e69ed-c794-4f4d-8b95-96b0e548fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplar_links = exemplar[17]['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "32103a16-17e2-4c51-b37e-4b62cd9e9e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn = defineConfusionMatrix(bot_graphs, exemplar_links)\n",
    "percision, recall, f1 = getScores(tp, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0bddd760-ae4f-45c2-baf9-4f17e14ba27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story 17 Output\n",
      "percision: 0.8089171974522293\n",
      "recall: 0.6318407960199005\n"
     ]
    }
   ],
   "source": [
    "print('Story 17 Output')\n",
    "print(f'percision: {percision}\\nrecall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "69185f2d-0e0d-4aa7-beb1-a6483ed03571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[9] = [17, 'John Lewis Dies', percision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d00f900-e0f8-4fd0-bb92-f0e01957ace0",
   "metadata": {},
   "source": [
    "## Story 19\n",
    "\n",
    "#### ASAP Rocky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b1c48396-12ec-4701-99f6-ef5dc81c09dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/toolkit_files/sgbot_19/cache/cache_2019-08-14.json', encoding = 'UTF-8')\n",
    "sgbot_19 = json.load(f)\n",
    "f.close()\n",
    "\n",
    "story = sgbot_19['2019-08-14']['stories'][0]\n",
    "unique_graphs = getUniqueGraphs(story)\n",
    "bot_graphs = getFormattedBotGraphs(unique_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "fa894581-e883-4f3e-9e04-cf2cb964f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplar_links = exemplar[19]['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "e92c0c6f-9589-42e4-aefb-94e974d55d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn = defineConfusionMatrix(bot_graphs, exemplar_links)\n",
    "percision, recall, f1 = getScores(tp, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "25144706-96b0-4a60-b2c5-ced61de56557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story 19 Output\n",
      "percision: 1.0\n",
      "recall: 0.1702127659574468\n"
     ]
    }
   ],
   "source": [
    "print('Story 19 Output')\n",
    "print(f'percision: {percision}\\nrecall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "f478ff8a-b18f-41ec-a332-60b271ad9bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[len(df)] = [19, 'ASAP Rocky Found Guilty in Sweeden', percision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "446405a5-ee5b-4232-bb1d-0c3513faccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/story_scores.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2eb8b-bd9d-42ce-95fd-3c9a7e0dc4f0",
   "metadata": {},
   "source": [
    "## Visualizing the Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad40ea5-77c0-48fc-aa3a-0b2bdeb5bc21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f20a81c-892c-47c0-a818-122365d8a07e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
